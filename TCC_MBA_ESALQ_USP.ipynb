{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelagem - TCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. Importações das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from scipy.stats import ks_2samp\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "# Função para calculo do KS\n",
    "def ks(y, p):\n",
    "    return np.round(ks_2samp(p[y == 1], p[y == 0])[0] * 100, 2)\n",
    "\n",
    "#import panther as pt\n",
    "#from panther.utils.memory_reduce import reduce_mem_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 02. Join e limpeza de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 2.1. Leitura de base sas\n",
    "df_cadastrais = pd.read_sas(r'/home/*/.sas7bdat')\n",
    "df_consultas  = pd.read_sas(r'/home/*/.sas7bdat')\n",
    "df_negativas  = pd.read_sas(r'/home/*/.sas7bdat')\n",
    "df_conceito   = pd.read_sas(r'/home/*/.sas7bdat')\n",
    "\n",
    "# 2.2. Join de tabelas\n",
    "df_enr = df_cadastrais.merge(df_consultas, left_on = [], right_on=[], how = 'left')\n",
    "df_enr = df_enr.merge(df_negativas, left_on = [], right_on=[], how = 'left')\n",
    "df_enr = df_enr.merge(df_conceito, left_on = [], right_on=[], how = 'left')\n",
    "\n",
    "# 2.3. Converte todos os caracteres das nomes das variáveis minúsculos em maiúsculo\n",
    "df_enr.columns = df_enr.columns.str.upper()\n",
    "\n",
    "# 2.4. Regex para remover variáveis de que contenhám...\n",
    "remov = 'VL|GO|OUA|GBOUT|GBPRI|FICHA|PCTT|CEP'\n",
    "\n",
    "# 2.5. Regex para remover variáveis de que contenhám...\n",
    "drop_vars_buraco_valor = df_enr.filter(regex = remov).columns.tolist()\n",
    "df_full = df_enr.drop(columns = drop_vars_buraco_valor , axis = 1)\n",
    "\n",
    "# 2.6. Salva base\n",
    "df_full2.to_csv('/home/*/.csv', index=False)\n",
    "\n",
    "# 2.7. Print dimensão\n",
    "print(\"Base possui {} linhas e {} colunas. \".format(\n",
    "    df_full2.shape[0], df_full2.shape[1]))\n",
    "\n",
    "# 2.8. View base\n",
    "df_full2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Leitura de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base possui 40050 linhas e 629 colunas. \n"
     ]
    }
   ],
   "source": [
    "# 3.1. Leitura base\n",
    "df = pd.read_csv(r'/home/*/.csv')\n",
    "df.head(10)\n",
    "\n",
    "# 3.2. Cria variável de Safra\n",
    "df[\"SAFRA\"] = pd.to_datetime(df[\"DT_T0\"], utc=True)\n",
    "df['SAFRA'] = df['SAFRA'].dt.strftime('%Y%m').astype('str')\n",
    "\n",
    "# 3.3. Filtra safras necessárias\n",
    "df = df[df['SAFRA'].isin(['202004','202005','202006','202007','202008','202009','202010','202011','202012','202101','202102','202103','202104','202105','202106'])]\n",
    "\n",
    "# 3.4. Print dimensão\n",
    "print(\"Base possui {} linhas e {} colunas. \".format(\n",
    "    df.shape[0], df.shape[1]))\n",
    "\n",
    "# 3.5. Renomeando variável\n",
    "df = df.rename(columns={\"...\": \"RESPOSTA\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Volumetria geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f65ac949d7eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 3.1 Verificar volume de registros por data (data pura, safra ou trimestre, definir de acordo com volumetria)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_vol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SAFRA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Frequência'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_vol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Volumetria Safra'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_vol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Frequência'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_vol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Frequência'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_vol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# 3.1.1 Verificar volume de registros por data (data pura, safra ou trimestre, definir de acordo com volumetria)\n",
    "df_vol = df.groupby(['SAFRA']).size().reset_index(name='Frequência')\n",
    "df_vol['Volumetria Safra'] = round(100*(df_vol['Frequência']/sum(df_vol['Frequência'])),2)\n",
    "df_vol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. Amostragem\n",
    "\n",
    "A base de dados será separada em 3 partes:\n",
    "- Treino: 70% da base de desenvolvimento\n",
    "- Teste: 30% da base de desenvolvimento\n",
    "- Out-Of-Time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NDOC', 'DT_T0', 'RESPOSTA']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.1. Colunas de referência (essas colunas não fazem sentido analisarmos)\n",
    "cols_ref = ['NDOC', 'DT_T0', 'RESPOSTA']#, 'SAFRA']\n",
    "cols_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2. Colunas que avaliaremos\n",
    "feats = [c for c in df.columns if c not in cols_ref] # Com a variável safra\n",
    "\n",
    "feats2 = feats.copy()\n",
    "feats2.remove('SAFRA') # Sem a variável safra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9024, 626)\n",
      "(9024,)\n"
     ]
    }
   ],
   "source": [
    "# 4.3. Amostra Out-Of-Time (OOT)\n",
    "oot = df[df['SAFRA'].isin(['202104','202105','202106'])]\n",
    "\n",
    "X_oot = oot[feats]       # Matriz X (features)\n",
    "y_oot = oot['RESPOSTA']  # Vetor y (target)\n",
    "\n",
    "print(X_oot.shape)\n",
    "print(y_oot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Base features Treino:  (21718, 626) \n",
      " Base features Treino:  (21718,) \n",
      "\n",
      "\n",
      " Base features Teste:  (9308, 626) \n",
      " Base features Teste:  (9308,)\n"
     ]
    }
   ],
   "source": [
    "# 4.4. Separando aleatoriamente entre o teste e treino\n",
    "df_desenv = df[~df['SAFRA'].isin(['202104','202105','202106'])]  # Filtro do desenvolvimento\n",
    "\n",
    "# Split aleatório na proporção de 80/30 (treino/teste)\n",
    "X_des, X_val, y_des, y_val = train_test_split(\n",
    "    df_desenv[feats],      # Matriz X do desenvolvimento (features)\n",
    "    df_desenv['RESPOSTA'], # vetor y do desenvolvimento (target)\n",
    "    test_size=0.3,         # proporção da amostra de teste\n",
    "    random_state=2022      # semente aleatória\n",
    ")\n",
    "\n",
    "print(' Base features Treino: ', X_des.shape, '\\n',\n",
    "      'Base features Treino: ', y_des.shape, '\\n\\n')\n",
    "\n",
    "print(' Base features Teste: ', X_val.shape, '\\n',\n",
    "      'Base features Teste: ', y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Volumetria amostras (DES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAFRA</th>\n",
       "      <th>Frequência</th>\n",
       "      <th>Volumetria Safra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202004</td>\n",
       "      <td>1648</td>\n",
       "      <td>7.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202005</td>\n",
       "      <td>1661</td>\n",
       "      <td>7.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202006</td>\n",
       "      <td>1687</td>\n",
       "      <td>7.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202007</td>\n",
       "      <td>1751</td>\n",
       "      <td>8.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202008</td>\n",
       "      <td>1724</td>\n",
       "      <td>7.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>202009</td>\n",
       "      <td>1780</td>\n",
       "      <td>8.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>202010</td>\n",
       "      <td>1862</td>\n",
       "      <td>8.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>202011</td>\n",
       "      <td>1870</td>\n",
       "      <td>8.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>202012</td>\n",
       "      <td>1898</td>\n",
       "      <td>8.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>202101</td>\n",
       "      <td>1893</td>\n",
       "      <td>8.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>202102</td>\n",
       "      <td>1924</td>\n",
       "      <td>8.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>202103</td>\n",
       "      <td>2020</td>\n",
       "      <td>9.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SAFRA  Frequência  Volumetria Safra\n",
       "0   202004        1648              7.59\n",
       "1   202005        1661              7.65\n",
       "2   202006        1687              7.77\n",
       "3   202007        1751              8.06\n",
       "4   202008        1724              7.94\n",
       "5   202009        1780              8.20\n",
       "6   202010        1862              8.57\n",
       "7   202011        1870              8.61\n",
       "8   202012        1898              8.74\n",
       "9   202101        1893              8.72\n",
       "10  202102        1924              8.86\n",
       "11  202103        2020              9.30"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.5. Verificar volume de registros por data (data pura, safra ou trimestre, definir de acordo com volumetria)\n",
    "\n",
    "DES = X_des.join(y_des)\n",
    "\n",
    "df_DES = DES.groupby(['SAFRA']).size().reset_index(name='Frequência')\n",
    "df_DES['Volumetria Safra'] = round(100*(df_DES['Frequência']/sum(df_DES['Frequência'])),2)\n",
    "df_DES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Volumetria amostras (VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAFRA</th>\n",
       "      <th>Frequência</th>\n",
       "      <th>Volumetria Safra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202004</td>\n",
       "      <td>685</td>\n",
       "      <td>7.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202005</td>\n",
       "      <td>707</td>\n",
       "      <td>7.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202006</td>\n",
       "      <td>705</td>\n",
       "      <td>7.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202007</td>\n",
       "      <td>765</td>\n",
       "      <td>8.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202008</td>\n",
       "      <td>793</td>\n",
       "      <td>8.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>202009</td>\n",
       "      <td>753</td>\n",
       "      <td>8.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>202010</td>\n",
       "      <td>763</td>\n",
       "      <td>8.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>202011</td>\n",
       "      <td>780</td>\n",
       "      <td>8.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>202012</td>\n",
       "      <td>852</td>\n",
       "      <td>9.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>202101</td>\n",
       "      <td>813</td>\n",
       "      <td>8.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>202102</td>\n",
       "      <td>840</td>\n",
       "      <td>9.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>202103</td>\n",
       "      <td>852</td>\n",
       "      <td>9.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SAFRA  Frequência  Volumetria Safra\n",
       "0   202004         685              7.36\n",
       "1   202005         707              7.60\n",
       "2   202006         705              7.57\n",
       "3   202007         765              8.22\n",
       "4   202008         793              8.52\n",
       "5   202009         753              8.09\n",
       "6   202010         763              8.20\n",
       "7   202011         780              8.38\n",
       "8   202012         852              9.15\n",
       "9   202101         813              8.73\n",
       "10  202102         840              9.02\n",
       "11  202103         852              9.15"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.6. Verificar volume de registros por data (data pura, safra ou trimestre, definir de acordo com volumetria)\n",
    "\n",
    "VAL = X_val.join(y_val)\n",
    "\n",
    "df_VAL = VAL.groupby(['SAFRA']).size().reset_index(name='Frequência')\n",
    "df_VAL['Volumetria Safra'] = round(100*(df_VAL['Frequência']/sum(df_VAL['Frequência'])),2)\n",
    "df_VAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Volumetria amostras (OOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAFRA</th>\n",
       "      <th>Frequência</th>\n",
       "      <th>Volumetria Safra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202104</td>\n",
       "      <td>2940</td>\n",
       "      <td>32.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202105</td>\n",
       "      <td>3006</td>\n",
       "      <td>33.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202106</td>\n",
       "      <td>3078</td>\n",
       "      <td>34.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SAFRA  Frequência  Volumetria Safra\n",
       "0  202104        2940             32.58\n",
       "1  202105        3006             33.31\n",
       "2  202106        3078             34.11"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.7. Verificar volume de registros por data (data pura, safra ou trimestre, definir de acordo com volumetria)\n",
    "\n",
    "oot2 = df[df['SAFRA'].isin(['202104','202105','202106'])]\n",
    "\n",
    "df_vol = oot2.groupby(['SAFRA']).size().reset_index(name='Frequência')\n",
    "df_vol['Volumetria Safra'] = round(100*(df_vol['Frequência']/sum(df_vol['Frequência'])),2)\n",
    "df_vol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. Univariada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. Verificando variáveis com valores missing (sem preenchimento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QtdMissing</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [QtdMissing, Total]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = pd.DataFrame(df[feats2].isna().sum(), columns = ['QtdMissing']) # Conta quantidade de NA/ausentes\n",
    "missing_values.sum()\n",
    "missing_values2 = pd.DataFrame(df[feats2].count(), columns = ['Total'])          # Total da columa preenchida\n",
    "\n",
    "missing_values_final = pd.merge(missing_values, missing_values2, left_index=True, right_index=True) # Join by index\n",
    "\n",
    "missing_values_final[missing_values['QtdMissing'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2. Removendo variáveis por concentração (valores iguais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feats2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a18c39545252>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Loop percorrendo todas as features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeats2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Percentual máximo de valores iguais\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feats2' is not defined"
     ]
    }
   ],
   "source": [
    "# 5.2.1. Remoção de variáveis por variabilidade\n",
    "\n",
    "feats_drop_univ = [] # Iniciando lista vazia para incluir features para serem removidas\n",
    "tresh_univ = 0.80 # Limite de variabilidade mínima (no máximo 90% de valores iguais)\n",
    "\n",
    "# 5.2.2. Loop percorrendo todas as features\n",
    "for f in feats2:\n",
    "    \n",
    "    # Percentual máximo de valores iguais\n",
    "    pct_max = df[f].value_counts(normalize = True).values[0]\n",
    "    \n",
    "    # Caso este percentual seja superior ao limite determinado, a feature será removida\n",
    "    if pct_max > tresh_univ:\n",
    "        feats_drop_univ.append(f) # Incluindo na lista a feature para ser dropada\n",
    "\n",
    "# 5.2.3. Print da quantidade de features dropadas\n",
    "print(f\"Drop Univariada: {len(feats_drop_univ)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features disponíveis: 304\n"
     ]
    }
   ],
   "source": [
    "# 5.2.4. Removendo as features dropadas da lista inicial (apenas as que usaremos para modelar)\n",
    "feats3 = [f for f in feats2 if f not in feats_drop_univ]\n",
    "\n",
    "# Quantidade de features disponíveis, após esta análise\n",
    "print(f\"Features disponíveis: {len(feats3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3. Univariada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariada_plus (dataset):\n",
    "    dataset = dataset.describe(percentiles = [0.99, 0.01, 0.05, 0.95])\n",
    "    \n",
    "    dataset = dataset.T\n",
    "    \n",
    "    dataset['VARIABILIDADE'] = np.where((dataset['99%'] == 0) | (dataset['99%'] == np.NaN), 'A. Sem variabilidade',\n",
    "         (np.where(dataset['1%'] == dataset['99%'], 'B. 98% igual',\n",
    "                   (np.where(dataset['5%'] == dataset['95%'], 'C. 90% igual', 'D. -OK')))))\n",
    "    \n",
    "    pct_max = df[f].value_counts(normalize = True).values[0]\n",
    "    if pct_max > tresh_univ:\n",
    "        feats_drop_univ.append(f) # Incluindo na lista a feature para ser dropada\n",
    "\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>1%</th>\n",
       "      <th>5%</th>\n",
       "      <th>50%</th>\n",
       "      <th>95%</th>\n",
       "      <th>99%</th>\n",
       "      <th>max</th>\n",
       "      <th>VARIABILIDADE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>QTSOCIOSPF</th>\n",
       "      <td>40050.0</td>\n",
       "      <td>2.160375</td>\n",
       "      <td>3.903218</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>D. -OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QTRESTREXC90D</th>\n",
       "      <td>40050.0</td>\n",
       "      <td>1.336479</td>\n",
       "      <td>6.326801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>D. -OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QTRESTREXC60D</th>\n",
       "      <td>40050.0</td>\n",
       "      <td>0.840499</td>\n",
       "      <td>4.356814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>D. -OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QTRESTRRESU24M</th>\n",
       "      <td>40050.0</td>\n",
       "      <td>11.909263</td>\n",
       "      <td>39.728988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>D. -OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QTRESTRRESU12M</th>\n",
       "      <td>40050.0</td>\n",
       "      <td>5.941498</td>\n",
       "      <td>21.440015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>D. -OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COCONSANUALSEG</th>\n",
       "      <td>40050.0</td>\n",
       "      <td>3.909938</td>\n",
       "      <td>1.583093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>D. -OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QTCONSORIGSEGUROS720D</th>\n",
       "      <td>40050.0</td>\n",
       "      <td>11.949738</td>\n",
       "      <td>13.115981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>D. -OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QTCONSORIGSEGUROS360D</th>\n",
       "      <td>40050.0</td>\n",
       "      <td>6.149888</td>\n",
       "      <td>7.729256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>D. -OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPMEDCONS5D</th>\n",
       "      <td>40050.0</td>\n",
       "      <td>-0.654152</td>\n",
       "      <td>1.239421</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>D. -OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QTRESTRAPOSULTSEMRESTR2</th>\n",
       "      <td>40050.0</td>\n",
       "      <td>1.707890</td>\n",
       "      <td>13.708311</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>D. -OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           count       mean        std  min   1%   5%  50%  \\\n",
       "QTSOCIOSPF               40050.0   2.160375   3.903218 -1.0 -1.0  0.0  2.0   \n",
       "QTRESTREXC90D            40050.0   1.336479   6.326801  0.0  0.0  0.0  0.0   \n",
       "QTRESTREXC60D            40050.0   0.840499   4.356814  0.0  0.0  0.0  0.0   \n",
       "QTRESTRRESU24M           40050.0  11.909263  39.728988  0.0  0.0  0.0  3.0   \n",
       "QTRESTRRESU12M           40050.0   5.941498  21.440015  0.0  0.0  0.0  1.0   \n",
       "...                          ...        ...        ...  ...  ...  ...  ...   \n",
       "COCONSANUALSEG           40050.0   3.909938   1.583093  0.0  0.0  0.0  5.0   \n",
       "QTCONSORIGSEGUROS720D    40050.0  11.949738  13.115981  0.0  0.0  0.0  8.0   \n",
       "QTCONSORIGSEGUROS360D    40050.0   6.149888   7.729256  0.0  0.0  0.0  4.0   \n",
       "TPMEDCONS5D              40050.0  -0.654152   1.239421 -2.0 -2.0 -2.0 -1.0   \n",
       "QTRESTRAPOSULTSEMRESTR2  40050.0   1.707890  13.708311 -2.0 -2.0 -1.0  0.0   \n",
       "\n",
       "                          95%    99%     max VARIABILIDADE  \n",
       "QTSOCIOSPF                5.0   11.0   304.0        D. -OK  \n",
       "QTRESTREXC90D             6.0   21.0   535.0        D. -OK  \n",
       "QTRESTREXC60D             4.0   14.0   334.0        D. -OK  \n",
       "QTRESTRRESU24M           50.0  161.0  1999.0        D. -OK  \n",
       "QTRESTRRESU12M           25.0   83.0  1311.0        D. -OK  \n",
       "...                       ...    ...     ...           ...  \n",
       "COCONSANUALSEG            5.0    5.0     5.0        D. -OK  \n",
       "QTCONSORIGSEGUROS720D    36.0   58.0   198.0        D. -OK  \n",
       "QTCONSORIGSEGUROS360D    19.0   31.0   117.0        D. -OK  \n",
       "TPMEDCONS5D               2.0    3.0     4.0        D. -OK  \n",
       "QTRESTRAPOSULTSEMRESTR2   7.0   35.0  1020.0        D. -OK  \n",
       "\n",
       "[304 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = univariada_plus(df[feats3]).sort_values(\"VARIABILIDADE\"); df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D. -OK    304\n",
       "Name: VARIABILIDADE, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "univariada_plus(df[feats3])['VARIABILIDADE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06. Tratamento de valores especiais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e24a118da050>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 6.1. Listando os valores especiais da base\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0minfer_spec_vl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec_vl_limit\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"\"\"Infere valores especiais como todos aqueles menores que o limite.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mspec_vl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# 6.1. Listando os valores especiais da base\n",
    "def infer_spec_vl(frame: pd.DataFrame, columns: list, spec_vl_limit: float = -1) -> list:\n",
    "    \"\"\"Infere valores especiais como todos aqueles menores que o limite.\"\"\"\n",
    "    spec_vl = set()\n",
    "    for col in columns:\n",
    "        if pd.api.types.is_numeric_dtype(frame[col]):\n",
    "            series = frame[col]\n",
    "            uniques = series[series <= spec_vl_limit].unique()\n",
    "            spec_vl.update(uniques.tolist())\n",
    "            \n",
    "    return list(spec_vl)\n",
    "\n",
    "\n",
    "spec_vl = infer_spec_vl(df, columns=feats, spec_vl_limit=-1)\n",
    "spec_vl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2. Tratando valores especiais: one-hot encode + substituição pela mediana\n",
    "for feature in feats3:\n",
    "    # Calculando a mediana após filtrar os valores especiais\n",
    "    median = X_des.loc[X_des[feature] > -1, feature].median()\n",
    "    \n",
    "    for vl in [-1]:\n",
    "        # Criando variáveis dummy (one-hot encode)\n",
    "        X_des[f'{feature}_{vl}'] = np.where(X_des[feature] == vl, 1, 0)\n",
    "        X_val[f'{feature}_{vl}'] = np.where(X_val[feature] == vl, 1, 0)\n",
    "        X_oot[f'{feature}_{vl}'] = np.where(X_oot[feature] == vl, 1, 0)\n",
    "    \n",
    "    # Substituindo o valor especial pela mediana na variável original\n",
    "    X_des[feature].replace({-1: median, -2: median}, inplace = True)\n",
    "    X_val[feature].replace({-1: median, -2: median}, inplace = True)\n",
    "    X_oot[feature].replace({-1: median, -2: median}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07. Modelos rápidos e escolha da técnica\n",
    "\n",
    "Nesta etapa serão testados 2 modelos rápidos de _Machine Learning_ distintos para a escolha da técnica que será utilizada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1. Random Search e modelos sem fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1.1. Conjuntos de hiperparâmetros para LGBM\n",
    "params_rs_lgbm = {\n",
    "    'num_leaves': list(range(2, 12, 1)),  # Quantidade máxima permitida de nós folhas (filhos) das árvores.\n",
    "    'learning_rate': list(np.logspace(np.log10(0.005), np.log10(0.2), num = 1000)), # Retornar 1000 números espaçados uniformemente em uma escala logarítmica.\n",
    "    'min_child_samples': list(range(1100, 2000, 100)),\n",
    "    'max_depth': list(range(3, 6, 1)),\n",
    "    'reg_alpha': list(np.logspace(np.log10(0.005), np.log10(5), num = 20)),\n",
    "    'reg_lambda': list(np.logspace(np.log10(0.005), np.log10(5), num = 20))\n",
    "    }\n",
    "\n",
    "# 7.1.2. Conjuntos de hiperparâmetros para LGBM\n",
    "params_rs_xgb = {\n",
    "    'num_leaves': list(range(2, 12, 1)),  # Quantidade máxima permitida de nós folhas (filhos) das árvores.\n",
    "    'learning_rate': list(np.logspace(np.log10(0.005), np.log10(0.2), num = 1000)), # Retornar 1000 números espaçados uniformemente em uma escala logarítmica.\n",
    "    'min_child_weight': list(range(100, 600, 50)),\n",
    "    'max_depth': list(range(3, 6, 1)),\n",
    "    'reg_alpha': list(np.logspace(np.log10(0.005), np.log10(5), num = 20)),\n",
    "    'reg_lambda': list(np.logspace(np.log10(0.005), np.log10(5), num = 20))\n",
    "    }\n",
    "\n",
    "# 7.1.3. Modelo LGBM \n",
    "lgb = LGBMClassifier(\n",
    "    random_state = 2022,  # semente aleatória\n",
    "    importance_type = 'gain'\n",
    ")\n",
    "\n",
    "# 7.1.4. Modelo XGBoost\n",
    "xgb = XGBClassifier(\n",
    "    random_state=2022,    # semente aleatória\n",
    "    importance_type = 'gain'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2. Random Search - LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomizedSearchCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b654b53d25ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Chamada do Random Search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m rs_lgbm = RandomizedSearchCV(\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Estimador escolhido\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mparam_distributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams_rs_lgbm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Distribuição dos hiperparâmetros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomizedSearchCV' is not defined"
     ]
    }
   ],
   "source": [
    "# 7.2.1. Função KS para utilizar dentro do random search\n",
    "# https://stackoverflow.com/questions/65967642/multi-scoring-input-randomizedsearchcv\n",
    "def ks_scoring(estimator, X, y):\n",
    "    y_pred = estimator.predict_proba(X)[:,0]\n",
    "    return ks_2samp( y_pred[y == 0], y_pred[y == 1] )[0]\n",
    "\n",
    "scoring = {'KS': ks_scoring , 'AUC': 'roc_auc'}\n",
    "\n",
    "# 7.2.2. Chamada do Random Search\n",
    "rs_lgbm = RandomizedSearchCV(\n",
    "    estimator = lgb, # Estimador escolhido\n",
    "    param_distributions = params_rs_lgbm, # Distribuição dos hiperparâmetros\n",
    "\n",
    "    scoring = scoring, \n",
    "        \n",
    "    # Função de métrica de performance\n",
    "    n_jobs = 10, # Quantidade de processamentos em paralelo\n",
    "    cv = 3, # Quantidades de folds (k-fold)\n",
    "    n_iter = 12, # Quantidade de iterações (fits) - Número de modelos\n",
    "    return_train_score = True, # Retorna a métrica (scoring) do treino no cv_results_\n",
    "    verbose = 1, # Print das etapas\n",
    "    random_state = 2022, # Semente aleatória,\n",
    "    refit = 'KS'\n",
    ").fit(X_des[feats3], y_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(importance_type='gain', learning_rate=0.13773996443434333,\n",
       "               max_depth=3, min_child_samples=1200, num_leaves=7,\n",
       "               random_state=2022, reg_alpha=0.044293339520504106,\n",
       "               reg_lambda=1.1678607345450605)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_lgbm.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3. Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_KS</th>\n",
       "      <th>mean_test_KS</th>\n",
       "      <th>rank_test_KS</th>\n",
       "      <th>mean_train_AUC</th>\n",
       "      <th>mean_test_AUC</th>\n",
       "      <th>rank_test_AUC</th>\n",
       "      <th>estabilidade_KS</th>\n",
       "      <th>estabilidade_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25.333147</td>\n",
       "      <td>{'reg_lambda': 1.1678607345450605, 'reg_alpha'...</td>\n",
       "      <td>0.572864</td>\n",
       "      <td>0.544633</td>\n",
       "      <td>1</td>\n",
       "      <td>0.863289</td>\n",
       "      <td>0.844151</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.049280</td>\n",
       "      <td>-0.022169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.996312</td>\n",
       "      <td>{'reg_lambda': 1.6799091431418902, 'reg_alpha'...</td>\n",
       "      <td>0.558957</td>\n",
       "      <td>0.544340</td>\n",
       "      <td>2</td>\n",
       "      <td>0.855474</td>\n",
       "      <td>0.842234</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.026149</td>\n",
       "      <td>-0.015477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25.359337</td>\n",
       "      <td>{'reg_lambda': 1.6799091431418902, 'reg_alpha'...</td>\n",
       "      <td>0.553819</td>\n",
       "      <td>0.544146</td>\n",
       "      <td>3</td>\n",
       "      <td>0.851693</td>\n",
       "      <td>0.843166</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.017465</td>\n",
       "      <td>-0.010012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25.934731</td>\n",
       "      <td>{'reg_lambda': 3.4759639808878022, 'reg_alpha'...</td>\n",
       "      <td>0.566766</td>\n",
       "      <td>0.544036</td>\n",
       "      <td>4</td>\n",
       "      <td>0.858062</td>\n",
       "      <td>0.843715</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.040104</td>\n",
       "      <td>-0.016720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21.663146</td>\n",
       "      <td>{'reg_lambda': 0.5644189458423441, 'reg_alpha'...</td>\n",
       "      <td>0.546910</td>\n",
       "      <td>0.542642</td>\n",
       "      <td>5</td>\n",
       "      <td>0.846640</td>\n",
       "      <td>0.841568</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.007803</td>\n",
       "      <td>-0.005990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time                                             params  \\\n",
       "6       25.333147  {'reg_lambda': 1.1678607345450605, 'reg_alpha'...   \n",
       "5       25.996312  {'reg_lambda': 1.6799091431418902, 'reg_alpha'...   \n",
       "9       25.359337  {'reg_lambda': 1.6799091431418902, 'reg_alpha'...   \n",
       "7       25.934731  {'reg_lambda': 3.4759639808878022, 'reg_alpha'...   \n",
       "10      21.663146  {'reg_lambda': 0.5644189458423441, 'reg_alpha'...   \n",
       "\n",
       "    mean_train_KS  mean_test_KS  rank_test_KS  mean_train_AUC  mean_test_AUC  \\\n",
       "6        0.572864      0.544633             1        0.863289       0.844151   \n",
       "5        0.558957      0.544340             2        0.855474       0.842234   \n",
       "9        0.553819      0.544146             3        0.851693       0.843166   \n",
       "7        0.566766      0.544036             4        0.858062       0.843715   \n",
       "10       0.546910      0.542642             5        0.846640       0.841568   \n",
       "\n",
       "    rank_test_AUC  estabilidade_KS  estabilidade_AUC  \n",
       "6               1        -0.049280         -0.022169  \n",
       "5               5        -0.026149         -0.015477  \n",
       "9               4        -0.017465         -0.010012  \n",
       "7               3        -0.040104         -0.016720  \n",
       "10              7        -0.007803         -0.005990  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 7.3.1. Tabela de resultados\n",
    "rs_results = pd.DataFrame(rs_lgbm.cv_results_)[['mean_fit_time', 'params', 'mean_train_KS', 'mean_test_KS', 'rank_test_KS', \n",
    "                                                                           'mean_train_AUC', 'mean_test_AUC', 'rank_test_AUC']]\n",
    "\n",
    "rs_results['estabilidade_KS'] = rs_results['mean_test_KS']/rs_results['mean_train_KS']-1\n",
    "rs_results['estabilidade_AUC'] = rs_results['mean_test_AUC']/rs_results['mean_train_AUC']-1\n",
    "\n",
    "rs_results = rs_results.sort_values('mean_test_KS', ascending = False)\n",
    "\n",
    "rs_results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_KS</th>\n",
       "      <th>mean_test_KS</th>\n",
       "      <th>rank_test_KS</th>\n",
       "      <th>mean_train_AUC</th>\n",
       "      <th>mean_test_AUC</th>\n",
       "      <th>rank_test_AUC</th>\n",
       "      <th>estabilidade_KS</th>\n",
       "      <th>estabilidade_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21.663146</td>\n",
       "      <td>{'reg_lambda': 0.5644189458423441, 'reg_alpha'...</td>\n",
       "      <td>0.546910</td>\n",
       "      <td>0.542642</td>\n",
       "      <td>5</td>\n",
       "      <td>0.846640</td>\n",
       "      <td>0.841568</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.007803</td>\n",
       "      <td>-0.005990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15.848270</td>\n",
       "      <td>{'reg_lambda': 2.416465119285876, 'reg_alpha':...</td>\n",
       "      <td>0.548414</td>\n",
       "      <td>0.542605</td>\n",
       "      <td>6</td>\n",
       "      <td>0.847583</td>\n",
       "      <td>0.841468</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.010592</td>\n",
       "      <td>-0.007216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.373140</td>\n",
       "      <td>{'reg_lambda': 0.5644189458423441, 'reg_alpha'...</td>\n",
       "      <td>0.537991</td>\n",
       "      <td>0.533942</td>\n",
       "      <td>11</td>\n",
       "      <td>0.840096</td>\n",
       "      <td>0.835975</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.007526</td>\n",
       "      <td>-0.004905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.935089</td>\n",
       "      <td>{'reg_lambda': 1.6799091431418902, 'reg_alpha'...</td>\n",
       "      <td>0.536491</td>\n",
       "      <td>0.533018</td>\n",
       "      <td>12</td>\n",
       "      <td>0.839957</td>\n",
       "      <td>0.836123</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.006473</td>\n",
       "      <td>-0.004565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time                                             params  \\\n",
       "10      21.663146  {'reg_lambda': 0.5644189458423441, 'reg_alpha'...   \n",
       "11      15.848270  {'reg_lambda': 2.416465119285876, 'reg_alpha':...   \n",
       "4       26.373140  {'reg_lambda': 0.5644189458423441, 'reg_alpha'...   \n",
       "1       15.935089  {'reg_lambda': 1.6799091431418902, 'reg_alpha'...   \n",
       "\n",
       "    mean_train_KS  mean_test_KS  rank_test_KS  mean_train_AUC  mean_test_AUC  \\\n",
       "10       0.546910      0.542642             5        0.846640       0.841568   \n",
       "11       0.548414      0.542605             6        0.847583       0.841468   \n",
       "4        0.537991      0.533942            11        0.840096       0.835975   \n",
       "1        0.536491      0.533018            12        0.839957       0.836123   \n",
       "\n",
       "    rank_test_AUC  estabilidade_KS  estabilidade_AUC  \n",
       "10              7        -0.007803         -0.005990  \n",
       "11              8        -0.010592         -0.007216  \n",
       "4              12        -0.007526         -0.004905  \n",
       "1              11        -0.006473         -0.004565  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 7.3.2. Filtrar apenas os resultados com menores estabilidades de 10% de queda de KS (modelos mais estáveis)\n",
    "rs_results_ = rs_results[rs_results['estabilidade_KS'] >= -0.012]\\\n",
    "    .sort_values('rank_test_KS') # Ordenação pelo ks (médio) da validação (teste)\n",
    "\n",
    "rs_results_.to_csv('/home/cdsw/rs_results_LGBM.csv', index=False)\n",
    "\n",
    "rs_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ranks = np.sort(rs_results_['rank_test_KS'].values) # Rank dos melhores modelos\n",
    "best_ranks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reg_lambda': 1.6799091431418902,\n",
       " 'reg_alpha': 0.06371374928515666,\n",
       " 'num_leaves': 4,\n",
       " 'min_child_samples': 1700,\n",
       " 'max_depth': 4,\n",
       " 'learning_rate': 0.015026636248522325}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_results_['params'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.4. Seleção do melhor modelo - lgbm\n",
    "\n",
    "Ajustaremos os modelos novamente na base de treino e testaremos na amostra de teste e de OOT, visando calcular a performance real em amostras nunca vistas pelo estimador. Consolidaremos os resultados a cada iteração e selecionaremos o melhor modelo em relação a performance e estabilidade nas bases de validações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Modelo: 005]:          KS TRAIN: 54.58  | KS TEST: 56.0  | KS OOT: 53.68  | ROC TRAIN: 84.56  | ROC OOS: 84.98  | ROC OOT: 83.64\n",
      "[Modelo: 006]:          KS TRAIN: 54.84  | KS TEST: 55.78  | KS OOT: 53.53  | ROC TRAIN: 84.72  | ROC OOS: 85.03  | ROC OOT: 83.75\n",
      "[Modelo: 011]:          KS TRAIN: 53.71  | KS TEST: 55.37  | KS OOT: 53.4  | ROC TRAIN: 83.99  | ROC OOS: 84.52  | ROC OOT: 83.2\n",
      "[Modelo: 012]:          KS TRAIN: 53.55  | KS TEST: 55.28  | KS OOT: 53.16  | ROC TRAIN: 83.91  | ROC OOS: 84.55  | ROC OOT: 83.21\n"
     ]
    }
   ],
   "source": [
    "# 7.4.1. Loop para calcular métricas dos melhores modelos\n",
    "\n",
    "best_results = pd.DataFrame() # DataFrame vazio que será preenchido com informações do processo\n",
    "\n",
    "# Loop pelos ranks dos melhores modelos\n",
    "for r in best_ranks:\n",
    "    \n",
    "    tic = datetime.now() # Início do processamento\n",
    "    print(f'[Modelo: {str(r).zfill(3)}]:          ', end = '')\n",
    "    \n",
    "    mask = rs_results_['rank_test_KS'] == r # objeto com o filtro do rank específico\n",
    "    params_ = rs_results_.loc[mask, 'params'].values[0] # selecionando os hiperparâmetros de acordo com o filtro\n",
    "\n",
    "    # LGBM\n",
    "    lgb = LGBMClassifier(\n",
    "        **params_, # atribuindo todos os hiperparâmetros (dicionário)\n",
    "        random_state = 2022, # semente aleatória\n",
    "        n_jobs = 10, # quantidade de processadores\n",
    "        importance_type = 'gain' # tipo de importancia\n",
    "    ).fit(X_des[feats3], y_des)\n",
    "\n",
    "    toc = datetime.now() # Final do processamento do modelo\n",
    "    lgb_time = toc - tic # tempo de processamento do modelo\n",
    "    \n",
    "    p_train_lgb = lgb.predict_proba(X_des[feats3])[:, 1] # probabilidade do treino\n",
    "    p_test_lgb = lgb.predict_proba(X_val[feats3])[:, 1] # probabilidade do teste\n",
    "    p_oot_lgb = lgb.predict_proba(X_oot[feats3])[:, 1] # probabilidade da OOT\n",
    "    \n",
    "    ks_train = ks(y_des, p_train_lgb) # KS treino\n",
    "    ks_test = ks(y_val, p_test_lgb) # KS teste\n",
    "    ks_oot = ks(y_oot, p_oot_lgb) # KS OOT\n",
    "    \n",
    "    # ROC\n",
    "    roc_train = np.round(100*roc_auc_score(y_des, lgb.predict_proba(X_des[feats3])[:, 1]),2)\n",
    "    roc_test = np.round(100*roc_auc_score(y_val, lgb.predict_proba(X_val[feats3])[:, 1]),2)\n",
    "    roc_oot = np.round(100*roc_auc_score(y_oot, lgb.predict_proba(X_oot[feats3])[:, 1]),2)\n",
    "        \n",
    "    # Juntando informações do processamento\n",
    "    best_results = pd.concat([\n",
    "        best_results,\n",
    "        pd.DataFrame({'rank': [r], 'time_process': [lgb_time], 'params': [params_], 'ks_train': [ks_train], 'ks_test': [ks_test], 'ks_oot': [ks_oot],\n",
    "                                                                                    'roc_train': [roc_train], 'roc_test': [roc_test], 'roc_oot': [roc_oot]})\n",
    "    ], axis = 0).reset_index(drop=True)\n",
    "    \n",
    "#    print(f'KS TRAIN: {ks_train}  |  KS TEST: {ks_test}  |  KS OOT: {ks_oot}')\n",
    "    print(f'KS TRAIN: {ks_train}  | KS TEST: {ks_test}  | KS OOT: {ks_oot}  | ROC TRAIN: {roc_train}  | ROC OOS: {roc_test}  | ROC OOT: {roc_oot}')\n",
    "\n",
    "# 7.4.2. Resetando o index\n",
    "best_results.reset_index(inplace = True)\n",
    "\n",
    "# 7.4.3. Criando métricas de estabilidade\n",
    "best_results['estab_test'] = best_results['ks_test']/best_results['ks_train']-1\n",
    "best_results['estab_oot'] = best_results['ks_oot']/best_results['ks_train']-1\n",
    "\n",
    "# 7.4.4. Salvando resultados\n",
    "best_results.to_pickle('/home/*/ascend_best_results_lgbm.pkl')\n",
    "best_results.to_csv('/home/*/Fast_KS_AMOSTRAS_lgb.csv')\n",
    "\n",
    "# Escolheremos o modelo 11 QUE é o 4 no rs_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.5. Verificando quantas variáveis importantes o modelo escolhido tem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> LightGBM\n",
      "KS TRAIN: 53.71\n",
      "KS TEST:  55.37\n",
      "KS OOT:   53.4\n",
      "Drop Importância Zero: 274\n",
      "Features disponíveis: 30\n"
     ]
    }
   ],
   "source": [
    "# 7.5.1. LGBM\n",
    "lgb = LGBMClassifier(**rs_results_['params'][4],\n",
    "random_state = 2022, # semente aleatória\n",
    "n_jobs = 10, # quantidade de processadores\n",
    "importance_type = 'gain'                     \n",
    ") # Valor da importância das features será o ganho delas nas árvores\n",
    "\n",
    "lgb.fit(X_des[feats3], y_des) # Fit do modelo com o X e y de treino\n",
    "\n",
    "# 7.5.2. Aplicando o modelo (probabilidade) nas amostras. (Lembrar que mau é 1)\n",
    "p_train_lgb = lgb.predict_proba(X_des[feats3])[:, 1]  # probabilidade do treino\n",
    "p_test_lgb = lgb.predict_proba(X_val[feats3])[:, 1]    # probabilidade do teste\n",
    "p_oot_lgb = lgb.predict_proba(X_oot[feats3])[:, 1]      # probabilidade da OOT\n",
    "\n",
    "# 7.5.3. Print do KS em cada uma das amostras\n",
    "print('--> LightGBM')\n",
    "print(f'KS TRAIN: {ks(y_des, p_train_lgb)}')\n",
    "print(f'KS TEST:  {ks(y_val, p_test_lgb)}')\n",
    "print(f'KS OOT:   {ks(y_oot, p_oot_lgb)}')\n",
    "\n",
    "# 7.5.4. Criar um DataFrame com as importâncias referenciando as features\n",
    "df_imp = pd.DataFrame({\n",
    "  'feature': feats3,\n",
    "  'importance': lgb.feature_importances_\n",
    "})\n",
    "\n",
    "# 7.5.5. Features com importância zero, vamos remove-las\n",
    "feats_drop_mfast = df_imp.loc[df_imp['importance'] == 0, 'feature'].tolist()\n",
    "\n",
    "# 7.5.6. Quantidade de features que serão dropadas por importância zerada\n",
    "print(f\"Drop Importância Zero: {len(feats_drop_mfast)}\")\n",
    "\n",
    "# 7.5.7. Ficar com todas as features iniciais, exceto as com importâncias zeradas\n",
    "feats4 = [f for f in feats3 if f not in feats_drop_mfast]\n",
    "\n",
    "# 7.5.8. Quantidade de features disponíveis após essa análise\n",
    "print(f\"Features disponíveis: {len(feats4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.6. Random Search - XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  36 out of  36 | elapsed:  8.7min finished\n"
     ]
    }
   ],
   "source": [
    "# 7.6.1. Função KS para utilizar dentro do random search\n",
    "def ks_scoring(estimator, X, y):\n",
    "    y_pred = estimator.predict_proba(X)[:,0]\n",
    "    return ks_2samp( y_pred[y == 0], y_pred[y == 1] )[0]\n",
    "\n",
    "scoring = {'KS': ks_scoring , 'AUC': 'roc_auc'}\n",
    "\n",
    "# 7.6.2. Chamada do Random Search\n",
    "rs_xgb = RandomizedSearchCV(\n",
    "    estimator = xgb, # Estimador escolhido\n",
    "    param_distributions = params_rs_xgb, # Distribuição dos hiperparâmetros\n",
    "    scoring = scoring, # Função de métrica de performance\n",
    "    n_jobs = 10, # Quantidade de processamentos em paralelo\n",
    "    cv = 3, # Quantidades de folds (k-fold)\n",
    "    n_iter = 12, # Quantidade de iterações (fits)\n",
    "    return_train_score = True, # Retorna a métrica (scoring) do treino no cv_results_\n",
    "    verbose = 1, # Print das etapas\n",
    "    random_state = 2022, # Semente aleatória\n",
    "    refit = 'KS'\n",
    ").fit(X_des[feats3], y_des)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.7. Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6708fc30e119>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 7.7.1. Tabela de resultados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m rs_results = pd.DataFrame(rs_xgb.cv_results_)[['mean_fit_time', 'params', 'mean_train_KS', 'mean_test_KS', 'rank_test_KS', \n\u001b[0m\u001b[1;32m      3\u001b[0m                                                                            'mean_train_AUC', 'mean_test_AUC', 'rank_test_AUC']]\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrs_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'estabilidade_KS'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_test_KS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mrs_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_train_KS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# 7.7.1. Tabela de resultados\n",
    "rs_results = pd.DataFrame(rs_xgb.cv_results_)[['mean_fit_time', 'params', 'mean_train_KS', 'mean_test_KS', 'rank_test_KS', \n",
    "                                                                           'mean_train_AUC', 'mean_test_AUC', 'rank_test_AUC']]\n",
    "\n",
    "rs_results['estabilidade_KS'] = rs_results['mean_test_KS']/rs_results['mean_train_KS']-1\n",
    "rs_results['estabilidade_AUC'] = rs_results['mean_test_AUC']/rs_results['mean_train_AUC']-1\n",
    "\n",
    "rs_results = rs_results.sort_values('mean_test_KS', ascending = False)\n",
    "\n",
    "rs_results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_KS</th>\n",
       "      <th>mean_test_KS</th>\n",
       "      <th>rank_test_KS</th>\n",
       "      <th>mean_train_AUC</th>\n",
       "      <th>mean_test_AUC</th>\n",
       "      <th>rank_test_AUC</th>\n",
       "      <th>estabilidade_KS</th>\n",
       "      <th>estabilidade_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>110.048843</td>\n",
       "      <td>{'reg_lambda': 0.5644189458423441, 'reg_alpha'...</td>\n",
       "      <td>0.552752</td>\n",
       "      <td>0.543137</td>\n",
       "      <td>5</td>\n",
       "      <td>0.849749</td>\n",
       "      <td>0.840792</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.017394</td>\n",
       "      <td>-0.010542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>105.137339</td>\n",
       "      <td>{'reg_lambda': 1.1678607345450605, 'reg_alpha'...</td>\n",
       "      <td>0.554351</td>\n",
       "      <td>0.542490</td>\n",
       "      <td>6</td>\n",
       "      <td>0.851390</td>\n",
       "      <td>0.840950</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.021396</td>\n",
       "      <td>-0.012263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61.964657</td>\n",
       "      <td>{'reg_lambda': 0.007192249441438314, 'reg_alph...</td>\n",
       "      <td>0.535919</td>\n",
       "      <td>0.534957</td>\n",
       "      <td>11</td>\n",
       "      <td>0.840118</td>\n",
       "      <td>0.836541</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.001795</td>\n",
       "      <td>-0.004257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108.493721</td>\n",
       "      <td>{'reg_lambda': 0.5644189458423441, 'reg_alpha'...</td>\n",
       "      <td>0.537429</td>\n",
       "      <td>0.531519</td>\n",
       "      <td>12</td>\n",
       "      <td>0.841477</td>\n",
       "      <td>0.836267</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.010997</td>\n",
       "      <td>-0.006192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time                                             params  \\\n",
       "10     110.048843  {'reg_lambda': 0.5644189458423441, 'reg_alpha'...   \n",
       "6      105.137339  {'reg_lambda': 1.1678607345450605, 'reg_alpha'...   \n",
       "0       61.964657  {'reg_lambda': 0.007192249441438314, 'reg_alph...   \n",
       "4      108.493721  {'reg_lambda': 0.5644189458423441, 'reg_alpha'...   \n",
       "\n",
       "    mean_train_KS  mean_test_KS  rank_test_KS  mean_train_AUC  mean_test_AUC  \\\n",
       "10       0.552752      0.543137             5        0.849749       0.840792   \n",
       "6        0.554351      0.542490             6        0.851390       0.840950   \n",
       "0        0.535919      0.534957            11        0.840118       0.836541   \n",
       "4        0.537429      0.531519            12        0.841477       0.836267   \n",
       "\n",
       "    rank_test_AUC  estabilidade_KS  estabilidade_AUC  \n",
       "10              9        -0.017394         -0.010542  \n",
       "6               8        -0.021396         -0.012263  \n",
       "0              11        -0.001795         -0.004257  \n",
       "4              12        -0.010997         -0.006192  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7.7.2. Filtrar apenas os resultados com menores estabilidades de 10% de queda de KS (modelos mais estáveis)\n",
    "rs_results_ = rs_results[rs_results['estabilidade_KS'] >= -0.0215]\\\n",
    "    .sort_values('rank_test_KS') # Ordenação pelo ks (médio) da validação (teste)\n",
    "\n",
    "rs_results_.to_csv('/home/cdsw/rs_results_XGB.csv', index=False)\n",
    "\n",
    "rs_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ranks = np.sort(rs_results_['rank_test_KS'].values) # Rank dos melhores modelos\n",
    "best_ranks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reg_lambda': 0.007192249441438314,\n",
       " 'reg_alpha': 0.06371374928515666,\n",
       " 'num_leaves': 9,\n",
       " 'min_child_weight': 500,\n",
       " 'max_depth': 5,\n",
       " 'learning_rate': 0.01716301828221557}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_results_['params'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.8. Seleção do melhor modelo - XGB\n",
    "\n",
    "Ajustaremos os modelos novamente na base de treino e testaremos na amostra de teste e de OOT, visando calcular a performance real em amostras nunca vistas pelo estimador. Consolidaremos os resultados a cada iteração e selecionaremos o melhor modelo em relação a performance e estabilidade nas bases de validações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Modelo: 005]:          KS TRAIN: 55.75  | KS TEST: 55.95  | KS OOT: 53.44  | ROC TRAIN: 85.43  | ROC OOS: 85.07  | ROC OOT: 83.96\n",
      "[Modelo: 006]:          KS TRAIN: 55.73  | KS TEST: 56.02  | KS OOT: 53.51  | ROC TRAIN: 85.29  | ROC OOS: 85.13  | ROC OOT: 83.92\n",
      "[Modelo: 011]:          KS TRAIN: 53.95  | KS TEST: 55.45  | KS OOT: 53.34  | ROC TRAIN: 84.35  | ROC OOS: 84.76  | ROC OOT: 83.43\n",
      "[Modelo: 012]:          KS TRAIN: 53.84  | KS TEST: 55.32  | KS OOT: 53.12  | ROC TRAIN: 84.06  | ROC OOS: 84.56  | ROC OOT: 83.23\n"
     ]
    }
   ],
   "source": [
    "# 7.8.1. Loop para calcular métricas dos melhores modelos\n",
    "\n",
    "best_results = pd.DataFrame() # DataFrame vazio que será preenchido com informações do processo\n",
    "\n",
    "# 7.8.2. Loop pelos ranks dos melhores modelos\n",
    "for r in best_ranks:\n",
    "    \n",
    "    tic = datetime.now() # Início do processamento\n",
    "    print(f'[Modelo: {str(r).zfill(3)}]:          ', end = '')\n",
    "    \n",
    "    mask = rs_results_['rank_test_KS'] == r # objeto com o filtro do rank específico\n",
    "    params_ = rs_results_.loc[mask, 'params'].values[0] # selecionando os hiperparâmetros de acordo com o filtro\n",
    "\n",
    "    # XGB\n",
    "    xgb = XGBClassifier(\n",
    "        **params_, # atribuindo todos os hiperparâmetros (dicionário)\n",
    "        random_state = 2022, # semente aleatória\n",
    "        n_jobs = 10, # quantidade de processadores\n",
    "        importance_type = 'gain' # tipo de importancia\n",
    "    ).fit(X_des[feats3], y_des)\n",
    "\n",
    "    toc = datetime.now() # Final do processamento do modelo\n",
    "    xgb_time = toc - tic # tempo de processamento do modelo\n",
    "    \n",
    "    p_train_xgb = xgb.predict_proba(X_des[feats3])[:, 1] # probabilidade do treino\n",
    "    p_test_xgb = xgb.predict_proba(X_val[feats3])[:, 1] # probabilidade do teste\n",
    "    p_oot_xgb = xgb.predict_proba(X_oot[feats3])[:, 1] # probabilidade da OOT\n",
    "    \n",
    "    ks_train = ks(y_des, p_train_xgb) # KS treino\n",
    "    ks_test = ks(y_val, p_test_xgb) # KS teste\n",
    "    ks_oot = ks(y_oot, p_oot_xgb) # KS OOT\n",
    "    \n",
    "    # ROC\n",
    "    roc_train = np.round(100*roc_auc_score(y_des, xgb.predict_proba(X_des[feats3])[:, 1]),2)\n",
    "    roc_test = np.round(100*roc_auc_score(y_val, xgb.predict_proba(X_val[feats3])[:, 1]),2)\n",
    "    roc_oot = np.round(100*roc_auc_score(y_oot, xgb.predict_proba(X_oot[feats3])[:, 1]),2)\n",
    "    \n",
    "    # Juntando informações do processamento\n",
    "    best_results = pd.concat([\n",
    "        best_results,\n",
    "        pd.DataFrame({'rank': [r], 'time_process': [xgb_time], 'params': [params_], 'ks_train': [ks_train], 'ks_test': [ks_test], 'ks_oot': [ks_oot],\n",
    "                                                                                    'roc_train': [roc_train], 'roc_test': [roc_test], 'roc_oot': [roc_oot]})\n",
    "    ], axis = 0).reset_index(drop=True)\n",
    "    \n",
    "    #print(f'KS TRAIN: {ks_train}  |  KS TEST: {ks_test}  |  KS OOT: {ks_oot}')\n",
    "    print(f'KS TRAIN: {ks_train}  | KS TEST: {ks_test}  | KS OOT: {ks_oot}  | ROC TRAIN: {roc_train}  | ROC OOS: {roc_test}  | ROC OOT: {roc_oot}')\n",
    "\n",
    "# 7.8.3. Resetando o index\n",
    "best_results.reset_index(inplace = True)\n",
    "\n",
    "# 7.8.4. Criando métricas de estabilidade\n",
    "best_results['estab_test'] = best_results['ks_test']/best_results['ks_train']-1\n",
    "best_results['estab_oot'] = best_results['ks_oot']/best_results['ks_train']-1\n",
    "\n",
    "# 7.8.5. Salvando resultados\n",
    "best_results.to_pickle('/home/cdsw/ascend_best_results_xgb.pkl')\n",
    "best_results.to_csv('/home/cdsw/Fast_KS_AMOSTRAS_xgb.csv')\n",
    "\n",
    "# Escolheremos o modelo 11 QUE é o 0 no rs_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Atenção! Refinaremos o modelo de LGBM, pois apresentou, minunciosamente, os melhores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.9. Verificando quantas variáveis importantes o modelo escolhido tem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> LightGBM\n",
      "KS TRAIN: 53.95\n",
      "KS TEST:  55.45\n",
      "KS OOT:   53.34\n",
      "Drop Importância Zero: 249\n",
      "Features disponíveis: 55\n"
     ]
    }
   ],
   "source": [
    "# 7.9.1. LGBM\n",
    "lgb = XGBClassifier(**rs_results_['params'][0],\n",
    "random_state = 2022, # semente aleatória\n",
    "n_jobs = 10, # quantidade de processadores\n",
    "importance_type = 'gain'                     \n",
    ") # Valor da importância das features será o ganho delas nas árvores\n",
    "\n",
    "lgb.fit(X_des[feats3], y_des) # Fit do modelo com o X e y de treino\n",
    "\n",
    "# 7.9.2. Aplicando o modelo (probabilidade) nas amostras. (Lembrar que mau é 1)\n",
    "p_train_lgb = lgb.predict_proba(X_des[feats3])[:, 1]  # probabilidade do treino\n",
    "p_test_lgb = lgb.predict_proba(X_val[feats3])[:, 1]    # probabilidade do teste\n",
    "p_oot_lgb = lgb.predict_proba(X_oot[feats3])[:, 1]      # probabilidade da OOT\n",
    "\n",
    "# 7.9.3. Print do KS em cada uma das amostras\n",
    "print('--> LightGBM')\n",
    "print(f'KS TRAIN: {ks(y_des, p_train_lgb)}')\n",
    "print(f'KS TEST:  {ks(y_val, p_test_lgb)}')\n",
    "print(f'KS OOT:   {ks(y_oot, p_oot_lgb)}')\n",
    "\n",
    "# 7.9.4. Criar um DataFrame com as importâncias referenciando as features\n",
    "df_imp = pd.DataFrame({\n",
    "  'feature': feats3,\n",
    "  'importance': lgb.feature_importances_\n",
    "})\n",
    "\n",
    "# 7.9.5. Features com importância zero, vamos remove-las\n",
    "feats_drop_mfast = df_imp.loc[df_imp['importance'] == 0, 'feature'].tolist()\n",
    "\n",
    "# 7.9.6. Quantidade de features que serão dropadas por importância zerada\n",
    "print(f\"Drop Importância Zero: {len(feats_drop_mfast)}\")\n",
    "\n",
    "# 7.9.7. Ficar com todas as features iniciais, exceto as com importâncias zeradas\n",
    "feats4 = [f for f in feats3 if f not in feats_drop_mfast]\n",
    "\n",
    "# 7.9.8. Quantidade de features disponíveis após essa análise\n",
    "print(f\"Features disponíveis: {len(feats4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08. Nova rodada de modelos apenas com LGBM aumentando o pull de hyperparametros pra ver o melhor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.1. Conjuntos de hiperparâmetros\n",
    "params_rs_lgbm = {\n",
    "    'num_leaves': list(range(3, 12, 2)),  # Quantidade máxima permitida de nós folhas (filhos) das árvores.\n",
    "    'learning_rate': list(np.logspace(np.log10(0.005), np.log10(0.3), num = 1000)), # Retornar 1000 números espaçados uniformemente em uma escala logarítmica.\n",
    "    'min_child_samples': list(range(1100, 2000, 100)),\n",
    "    'max_depth': list(range(3, 6, 1)),\n",
    "    'n_estimators': list(range(100, 800, 100)),\n",
    "    'min_child_weight': list(np.logspace(np.log10(70), np.log10(650), num = 1000)),\n",
    "    'subsample': list(np.logspace(np.log10(0.5), np.log10(1), num = 20)),\n",
    "    'colsample_bytree': list(np.logspace(np.log10(0.5), np.log10(1), num = 20)),\n",
    "    'reg_alpha': list(np.logspace(np.log10(0.005), np.log10(8), num = 100)),\n",
    "    'reg_lambda': list(np.logspace(np.log10(0.005), np.log10(8), num = 100)),\n",
    "    'min_split_gain': list(range(0, 20, 2)),\n",
    "    'gamma': list(range(1, 7, 1)),\n",
    "}\n",
    "\n",
    "        \n",
    "# 8.2. LGBM\n",
    "lgb = LGBMClassifier(\n",
    "    random_state = 2022,  # semente aleatória\n",
    "    importance_type = 'gain'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 500 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed: 41.2min\n"
     ]
    }
   ],
   "source": [
    "# 8.3. Função KS para utilizar dentro do random search\n",
    "def ks_scoring(estimator, X, y):\n",
    "    y_pred = estimator.predict_proba(X)[:,0]\n",
    "    return ks_2samp( y_pred[y == 0], y_pred[y == 1] )[0]\n",
    "\n",
    "scoring = {'KS': ks_scoring , 'AUC': 'roc_auc'}\n",
    "\n",
    "# 8.4. Chamada do Random Search\n",
    "rs_lgbm = RandomizedSearchCV(\n",
    "    estimator = lgb, # Estimador escolhido\n",
    "    param_distributions = params_rs_lgbm, # Distribuição dos hiperparâmetros\n",
    "    scoring = scoring, # Função de métrica de performance\n",
    "    n_jobs = 10, # Quantidade de processamentos em paralelo\n",
    "    cv = 3, # Quantidades de folds (k-fold)\n",
    "    n_iter = 500, # Quantidade de iterações (fits) - Número de modelos\n",
    "    return_train_score = True, # Retorna a métrica (scoring) do treino no cv_results_\n",
    "    verbose = 1, # Print das etapas\n",
    "    random_state = 2022, # Semente aleatória\n",
    "    refit = 'KS'\n",
    ").fit(X_des[feats3], y_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.5. Tabela de resultados\n",
    "rs_results = pd.DataFrame(rs_lgbm.cv_results_)[['mean_fit_time', 'params', 'mean_train_KS', 'mean_test_KS', 'rank_test_KS', \n",
    "                                                                           'mean_train_AUC', 'mean_test_AUC', 'rank_test_AUC']]\n",
    "\n",
    "rs_results['estabilidade_KS'] = rs_results['mean_test_KS']/rs_results['mean_train_KS']-1\n",
    "rs_results['estabilidade_AUC'] = rs_results['mean_test_AUC']/rs_results['mean_train_AUC']-1\n",
    "\n",
    "rs_results = rs_results.sort_values('mean_test_KS', ascending = False)\n",
    "\n",
    "rs_results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_results.to_csv('/home/cdsw/REFINO.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.6. Filtrar apenas os resultados com menores estabilidades de 10% de queda de KS (modelos mais estáveis)\n",
    "rs_results_ = rs_results[rs_results['estabilidade_KS'] >= -0.012]\\\n",
    "    .sort_values('rank_test_KS') # Ordenação pelo ks (médio) da validação (teste)\n",
    "\n",
    "rs_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ranks = np.sort(rs_results_['rank_test_KS'].values) # Rank dos melhores modelos\n",
    "best_ranks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.7. Loop para calcular métricas dos melhores modelos\n",
    "\n",
    "best_results = pd.DataFrame() # DataFrame vazio que será preenchido com informações do processo\n",
    "\n",
    "# 8.8. Loop pelos ranks dos melhores modelos\n",
    "for r in best_ranks:\n",
    "    \n",
    "    tic = datetime.now() # Início do processamento\n",
    "    print(f'[Modelo: {str(r).zfill(3)}]:          ', end = '')\n",
    "    \n",
    "    mask = rs_results_['rank_test_KS'] == r # objeto com o filtro do rank específico\n",
    "    params_ = rs_results_.loc[mask, 'params'].values[0] # selecionando os hiperparâmetros de acordo com o filtro\n",
    "\n",
    "    # LGBM\n",
    "    lgb = LGBMClassifier(\n",
    "        **params_, # atribuindo todos os hiperparâmetros (dicionário)\n",
    "        random_state = 2022, # semente aleatória\n",
    "        n_jobs = 10,\n",
    "        importance_type = 'gain'\n",
    "        # quantidade de processadores\n",
    "    ).fit(X_des[feats3], y_des)\n",
    "\n",
    "    toc = datetime.now() # Final do processamento do modelo\n",
    "    lgb_time = toc - tic # tempo de processamento do modelo\n",
    "    \n",
    "    p_train_lgb = lgb.predict_proba(X_des[feats3])[:, 1] # probabilidade do treino\n",
    "    p_test_lgb = lgb.predict_proba(X_val[feats3])[:, 1] # probabilidade do teste\n",
    "    p_oot_lgb = lgb.predict_proba(X_oot[feats3])[:, 1] # probabilidade da OOT\n",
    "    \n",
    "    ks_train = ks(y_des, p_train_lgb) # KS treino\n",
    "    ks_test = ks(y_val, p_test_lgb) # KS teste\n",
    "    ks_oot = ks(y_oot, p_oot_lgb) # KS OOT\n",
    "    \n",
    "    # ROC\n",
    "    roc_train = np.round(100*roc_auc_score(y_des, lgb.predict_proba(X_des[feats3])[:, 1]),2)\n",
    "    roc_test = np.round(100*roc_auc_score(y_val, lgb.predict_proba(X_val[feats3])[:, 1]),2)\n",
    "    roc_oot = np.round(100*roc_auc_score(y_oot, lgb.predict_proba(X_oot[feats3])[:, 1]),2)\n",
    "    \n",
    "    # Juntando informações do processamento\n",
    "    best_results = pd.concat([\n",
    "        best_results,\n",
    "        pd.DataFrame({'rank': [r], 'time_process': [lgb_time], 'params': [params_], 'ks_train': [ks_train], 'ks_test': [ks_test], 'ks_oot': [ks_oot],\n",
    "                                                                                    'roc_train': [roc_train], 'roc_test': [roc_test], 'roc_oot': [roc_oot]})\n",
    "    ], axis = 0).reset_index(drop=True)\n",
    "    \n",
    "#    print(f'KS TRAIN: {ks_train}  |  KS TEST: {ks_test}  |  KS OOT: {ks_oot}')\n",
    "    print(f'KS TRAIN: {ks_train}  | KS TEST: {ks_test}  | KS OOT: {ks_oot}  | ROC TRAIN: {roc_train}  | ROC OOS: {roc_test}  | ROC OOT: {roc_oot}')\n",
    "\n",
    "# 8.8. Resetando o index\n",
    "best_results.reset_index(inplace = True)\n",
    "\n",
    "# 8.9. Criando métricas de estabilidade\n",
    "best_results['estab_test'] = best_results['ks_test']/best_results['ks_train']-1\n",
    "best_results['estab_oot'] = best_results['ks_oot']/best_results['ks_train']-1\n",
    "\n",
    "# 8.10. Salvando resultados\n",
    "best_results.to_pickle('/home/*/ascend_best_results_refinao.pkl')\n",
    "best_results.to_csv('/home/*/ascend_refinao.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09. Remoção por Importância"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lendo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results2 = pd.read_csv('/home/cdsw/ascend_refinao.csv');\n",
    "best_results2\n",
    "# Baseado nessa tabela escolhar o melhor algoritmo e faça os testes abaixo pra ver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results2['params'][184]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando o modelo LGBM selecionado\n",
    "#lgb = LGBMClassifier(**best_results['params'][40],\n",
    "lgb = LGBMClassifier(subsample = 0.7746298211333279, reg_lambda = 0.04676440937077718, reg_alpha = 5.937868749792548, num_leaves = 3, n_estimators = 100, min_split_gain = 16, min_child_weight = 378.8502727624012, min_child_samples = 1900, max_depth = 4, learning_rate = 0.012167884278142268, gamma = 4, colsample_bytree = 0.8332620063985445,\n",
    "random_state = 2022, # semente aleatória\n",
    "n_jobs = 10, # quantidade de processadores\n",
    "importance_type = 'gain'                     \n",
    ") # Valor da importância das features será o ganho delas nas árvores\n",
    "\n",
    "lgb.fit(X_des[feats3], y_des) # Fit do modelo com o X e y de treino\n",
    "\n",
    "# Aplicando o modelo (probabilidade) nas amostras. (Lembrar que mau é 1)\n",
    "p_train_lgb = lgb.predict_proba(X_des[feats3])[:, 1]  # probabilidade do treino\n",
    "p_test_lgb = lgb.predict_proba(X_val[feats3])[:, 1]    # probabilidade do teste\n",
    "p_oot_lgb = lgb.predict_proba(X_oot[feats3])[:, 1]      # probabilidade da OOT\n",
    "\n",
    "# Print do KS em cada uma das amostras\n",
    "print('--> LightGBM')\n",
    "print(f'KS TRAIN: {ks(y_des, p_train_lgb)}')\n",
    "print(f'KS TEST:  {ks(y_val, p_test_lgb)}')\n",
    "print(f'KS OOT:   {ks(y_oot, p_oot_lgb)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1. Importância zerada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2. Importância das variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um DataFrame com as importâncias referenciando as features\n",
    "\n",
    "df_imp = pd.DataFrame({\n",
    "  'feature': feats3,\n",
    "  'importance': lgb.feature_importances_\n",
    "})\n",
    "\n",
    "# Ordenando da mais importante para a menos\n",
    "df_imp.sort_values('importance', ascending = False, inplace=True)\n",
    "\n",
    "# Print 5 features mais importantes\n",
    "df_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.3. Freq. Importância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequência da importância \n",
    "df_imp['importance'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.4. Remover variáveis zeradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.4.1. Features com importância zero, vamos remove-las\n",
    "feats_drop_mfast = df_imp.loc[df_imp['importance'] == 0, 'feature'].tolist()\n",
    "\n",
    "# 9.4.2. Quantidade de features que serão dropadas por importância zerada\n",
    "print(f\"Drop Importância Zero: {len(feats_drop_mfast)}\")\n",
    "\n",
    "# 9.4.3. Ficar com todas as features iniciais, exceto as com importâncias zeradas\n",
    "feats4 = [f for f in feats3 if f not in feats_drop_mfast]\n",
    "\n",
    "# 9.4.4. Quantidade de features disponíveis após essa análise\n",
    "print(f\"Features disponíveis: {len(feats4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.5. Verificando modelo pós remoção de variáveis com importância zerada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.5.1. LGBM\n",
    "lgb = LGBMClassifier(subsample = 0.7746298211333279, reg_lambda = 0.04676440937077718, reg_alpha = 5.937868749792548, num_leaves = 3, n_estimators = 100, min_split_gain = 16, min_child_weight = 378.8502727624012, min_child_samples = 1900, max_depth = 4, learning_rate = 0.012167884278142268, gamma = 4, colsample_bytree = 0.8332620063985445,\n",
    "random_state = 2022, # semente aleatória\n",
    "n_jobs = 10, # quantidade de processadores\n",
    "importance_type = 'gain'\n",
    ") # Valor da importância das features será o ganho delas nas árvores\n",
    "\n",
    "lgb.fit(X_des[feats4], y_des) # Fit do modelo com o X e y de treino\n",
    "\n",
    "# 9.5.2. Aplicando o modelo (probabilidade) nas amostras. (Lembrar que mau é 1)\n",
    "p_train_lgb = lgb.predict_proba(X_des[feats4])[:, 1]  # probabilidade do treino\n",
    "p_test_lgb = lgb.predict_proba(X_val[feats4])[:, 1]    # probabilidade do teste\n",
    "p_oot_lgb = lgb.predict_proba(X_oot[feats4])[:, 1]      # probabilidade da OOT\n",
    "\n",
    "# 9.5.3. Print do KS em cada uma das amostras\n",
    "print('--> LightGBM')\n",
    "print(f'KS TRAIN: {ks(y_des, p_train_lgb)}')\n",
    "print(f'KS TEST:  {ks(y_val, p_test_lgb)}')\n",
    "print(f'KS OOT:   {ks(y_oot, p_oot_lgb)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.6. Importancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.6.1. Criar um DataFrame com as importâncias referenciando as features\n",
    "df_imp = pd.DataFrame({\n",
    "  'feature': feats4,\n",
    "  'importance': lgb.feature_importances_\n",
    "})\n",
    "\n",
    "# 9.6.2. Ordenando da mais importante para a menos\n",
    "df_imp.sort_values('importance', ascending = False, inplace=True)\n",
    "\n",
    "# 9.6.3. Print 5 features mais importantes\n",
    "df_imp['Perc'] = df_imp['importance']/sum(df_imp['importance'])\n",
    "df_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Remoção de variável recursirvamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.1.1 Função para retirada de vars. recursiva\n",
    "def recursive_selection(\n",
    "    features: list,\n",
    "    X_train: pd.DataFrame,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    y_test: pd.Series,\n",
    "    step: int = 5,\n",
    "    max_ks_diff: int = 2,\n",
    "    n_feats: int = 50\n",
    "):\n",
    "    \"\"\"\n",
    "    Seleção sequencial de variáveis pelo feature importance, observando o KS a cada iteração.\n",
    "    \"\"\"\n",
    "    feats_ = features.copy() # Cópia da lista de features (caso dê algum problema, temos a lista original)\n",
    "    i = 0 # indicador de contagem (iniciando em zero)\n",
    "    summary_rfe = pd.DataFrame() # DataFrame que será inputado os resultados sumarizado do processo\n",
    "    feat_drop = [] # Lista de features para drop, inicialmente vazia\n",
    "    print(f'Número de variáveis inicial: {len(feats_)}')\n",
    "\n",
    "    # Loop infinito (até algum critério de parada ser atendido)\n",
    "    while True:\n",
    "\n",
    "        tic = datetime.now() # início do processamento\n",
    "\n",
    "        # Prints iniciais\n",
    "        print(f'Iteração {i+1}:') # Iteração\n",
    "        print(f'  -> {len(feat_drop)} features removidas: {feat_drop}') # Features que serão dropadas\n",
    "        print(f'  -> {len(feats_)} features disponíveis') # Features disponíveis\n",
    "\n",
    "        # LGBM\n",
    "        #lgb = LGBMClassifier(**best_results['params'][40],\n",
    "        lgb = LGBMClassifier(subsample = 0.7746298211333279, reg_lambda = 0.04676440937077718, reg_alpha = 5.937868749792548, num_leaves = 3, n_estimators = 100, min_split_gain = 16, min_child_weight = 378.8502727624012, min_child_samples = 1900, max_depth = 4, learning_rate = 0.012167884278142268, gamma = 4, colsample_bytree = 0.8332620063985445,\n",
    "\n",
    "                random_state = 2022, # semente aleatória\n",
    "                n_jobs = 10, # quantidade de processadores\n",
    "                importance_type = 'gain').fit(X_train[feats_], y_train) # Fit do modelo com o X e y de treino\n",
    "\n",
    "        toc = datetime.now() # final do processamento\n",
    "        lgb_time = toc - tic # tempo total de processamento\n",
    "        print(f'Tempo de processamento do modelo: {lgb_time}')\n",
    "\n",
    "        p_train_lgb = lgb.predict_proba(X_train[feats_])[:, 1] # probabilidade do treino\n",
    "        p_test_lgb = lgb.predict_proba(X_test[feats_])[:, 1] # probabilidade do teste\n",
    "        p_oot_lgb = lgb.predict_proba(X_oot[feats_])[:, 1] # probabilidade da OOT\n",
    "\n",
    "        # KS da Out-of-sample (test)\n",
    "        ks_test = ks(y_test, p_test_lgb)\n",
    "        print(f'  -> KS test: {ks_test}')\n",
    "\n",
    "        # KS de referência (caso seja a primeira iteração - modelo inicial)\n",
    "        if i == 0:\n",
    "            ks_ref = ks_test\n",
    "            print(f'  -> KS de referência: {ks_ref}')\n",
    "\n",
    "        # Concatenação (union) do dataframe de resumo do RFE\n",
    "        summary_rfe = pd.concat([\n",
    "            summary_rfe, \n",
    "            pd.DataFrame({\n",
    "                'iteration': [i], # iteração\n",
    "                'feature_drop': [feat_drop], # lista das features que serão removidas\n",
    "                'feature': [feats_], # lista das features disponíveis\n",
    "                'importance': [lgb.feature_importances_.tolist()], # importancia das features disponíveis\n",
    "                'ks_train': [ks(y_train, p_train_lgb)], # KS do treino\n",
    "                'ks_test':[ ks(y_test, p_test_lgb)], # KS do teste\n",
    "                'ks_oot': [ ks(y_oot, p_oot_lgb)], # KS da OOT\n",
    "                'time_process': [lgb_time] # tempo de processamento do modelo\n",
    "            })\n",
    "        ], axis = 0) # append de linhas\n",
    "\n",
    "        # DataFrame com as importâncias referenciando as features\n",
    "        df_imp = pd.DataFrame({'feature': feats_, 'importance': lgb.feature_importances_})\\\n",
    "            .sort_values('importance', ascending = False) # Ordenando da mais importante para a menos\n",
    "\n",
    "        # Caso tenha alguma feature com importância zerada, será considerada como a de menor importância\n",
    "        if np.sum(df_imp['importance'] == 0) > 0:\n",
    "            feat_drop = df_imp.loc[df_imp['importance'] == 0, 'feature'].values # lista de features com importância zerada\n",
    "        else:\n",
    "            feat_drop = df_imp['feature'].values[-step:] # lista das 'step' features com menor importância\n",
    "\n",
    "        # Atualizando a lista de features disponíveis -> removendo as features de drop\n",
    "        feats_ = [f for f in feats_ if f not in feat_drop]\n",
    "\n",
    "        # Critério de parada da diferença de KS\n",
    "        if ks_ref - ks_test >= max_ks_diff:\n",
    "            print(f'Fim do processamento -> Diferença de KS maior que {max_ks_diff} pontos')\n",
    "            break\n",
    "\n",
    "        # Critério de parada da quantidade de features disponíveis finais\n",
    "        if len(feats_) < n_feats:\n",
    "            print('Fim do processamento -> Número de features atingido')\n",
    "            break\n",
    "\n",
    "        i += 1 # Próxima iteração\n",
    "        toc2 = datetime.now() # final processamento da iteração\n",
    "        time_process = toc2 - tic # tempo total de processamento da iteração\n",
    "        print(f'  -> Tempo de processamento total: {time_process}', end = '\\n\\n')\n",
    "    \n",
    "    return summary_rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.1.2. Aplicando função para retirada de vars. recursiva\n",
    "summary = recursive_selection(\n",
    "    features = feats4,\n",
    "    X_train = X_des,\n",
    "    X_test = X_val,\n",
    "    y_train = y_des,\n",
    "    y_test = y_val,\n",
    "    step = 1,          # De quantas em quantas variáveis faremos a recursão? (1 em 1)\n",
    "    max_ks_diff = 0.2, # Qual diferença máxima de KS estamos dispostos a aceitar? (1 ponto, ou seja estou disposto a perder um 1 de ks desde que meu modelo fique com menos variáveis - CUIDADO)\n",
    "    n_feats = 5        # Qual número de features final queremos?\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe sumarizando o processo de RFE\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats5 = summary['feature'].values[2]\n",
    "\n",
    "# Verificando a iteração onde o processo determinou o melhor modelo\n",
    "#feats5 = summary['feature'].values[-1]\n",
    "#len(feats)\n",
    "feats5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.1.3. Retreino do novo modelo com as features restantes\n",
    "lgb = LGBMClassifier(subsample = 0.7746298211333279, reg_lambda = 0.04676440937077718, reg_alpha = 5.937868749792548, num_leaves = 3, n_estimators = 100, min_split_gain = 16, min_child_weight = 378.8502727624012, min_child_samples = 1900, max_depth = 4, learning_rate = 0.012167884278142268, gamma = 4, colsample_bytree = 0.8332620063985445,\n",
    "random_state = 2022, # semente aleatória\n",
    "n_jobs = 10, # quantidade de processadores\n",
    "importance_type = 'gain'\n",
    ")\n",
    "lgb.fit(X_des[feats5], y_des) # Fit do modelo com o X e y de treino\n",
    "\n",
    "# 10.1.4. Aplicando o modelo (probabilidade) nas amostras. (Lembrar que mau é 1)\n",
    "p_train_lgb = lgb.predict_proba(X_des[feats5])[:, 1]  # probabilidade do treino\n",
    "p_test_lgb = lgb.predict_proba(X_val[feats5])[:, 1]    # probabilidade do teste\n",
    "p_oot_lgb = lgb.predict_proba(X_oot[feats5])[:, 1]      # probabilidade da OOT\n",
    "\n",
    "# 10.1.5. Print do KS em cada uma das amostras\n",
    "print('--> LightGBM')\n",
    "print(f'KS TRAIN: {ks(y_des, p_train_lgb)}')\n",
    "print(f'KS TEST:  {ks(y_val, p_test_lgb)}')\n",
    "print(f'KS OOT:   {ks(y_oot, p_oot_lgb)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.1.6. Criar um DataFrame com as importâncias referenciando as features\n",
    "df_imp = pd.DataFrame({\n",
    "  'feature': feats5,\n",
    "  'importance': lgb.feature_importances_\n",
    "})\n",
    "\n",
    "# 10.1.7. Ordenando da mais importante para a menos\n",
    "df_imp.sort_values('importance', ascending = False, inplace=True)\n",
    "\n",
    "# 10.1.8. Print 5 features mais importantes\n",
    "df_imp['Perc'] = df_imp['importance']/sum(df_imp['importance'])\n",
    "df_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X__des = X_des[feats5].copy(); X__val = X_val[feats5].copy(); X__oot = X_oot[feats5].copy()\n",
    "\n",
    "# 11.1. Construção do LGBM\n",
    "lgb = LGBMClassifier(subsample = 0.7746298211333279, reg_lambda = 0.04676440937077718, reg_alpha = 5.937868749792548, num_leaves = 3, n_estimators = 100, min_split_gain = 16, min_child_weight = 378.8502727624012, min_child_samples = 1900, max_depth = 4, learning_rate = 0.012167884278142268, gamma = 4, colsample_bytree = 0.8332620063985445,\n",
    "random_state = 2022, # semente aleatória\n",
    "n_jobs = 10, # quantidade de processadores\n",
    "importance_type = 'gain'\n",
    ")\n",
    "lgb.fit(X__des, y_des) # Fit do modelo com o X e y de treino\n",
    "\n",
    "# 11.2. Aplicando o modelo (probabilidade) nas amostras.\n",
    "p_train_lgb = lgb.predict_proba(X__des)[:, 1] # probabilidade do treino\n",
    "p_test_lgb = lgb.predict_proba(X__val)[:, 1]  # probabilidade do teste\n",
    "p_oot_lgb = lgb.predict_proba(X__oot)[:, 1]   # probabilidade da OOT\n",
    "\n",
    "# 11.3. Print do KS em cada uma das amostras\n",
    "print('--> LightGBM')\n",
    "print(f'KS TRAIN: {ks(y_des, p_train_lgb)}')\n",
    "print(f'KS TEST:  {ks(y_val, p_test_lgb)}')\n",
    "print(f'KS OOT:   {ks(y_oot, p_oot_lgb)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary plot: Gráfico com a distribuição do (impacto) SHAP values (eixo x) para cada feature (eixo y) da mais importânte para a menos importante. \n",
    "# As cores representam a amplitude do valor da feature. Quanto mais próximo do verde maior é o valor, e quanto mais próximo do azul menor é o valor.\n",
    "\n",
    "tree_explainer = shap.TreeExplainer(lgb) # Conversão do modelo para uma árvore explicativa do SHAP (tree explainer)\n",
    "shap_values_tree = tree_explainer.shap_values(X__des) # Estimativas do shap values através do tree explainer\n",
    "shap_obj_tree = tree_explainer(X__des) # Aplicando na matriz especificada (X_shap)\n",
    "\n",
    "shap.summary_plot(\n",
    "    shap_values = shap_values_tree[1], # Valores do SHAP visando o target 1 (quanto maior o shap value maiores as chances de 1)\n",
    "    features = X__des, # DataFrame para extrair informações das features\n",
    "    plot_type = 'dot', # Tipo de plot (pontos)\n",
    "    cmap = 'vlag', # Paleta de cores (azul-verde)\n",
    "    max_display = 30, # Máximo de features para mostrar no gráfico (mais importântes),\n",
    "    plot_size=[8,6],\n",
    "    show=False\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.savefig('SHAP.png', format='png', dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Escorando BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12.1. Construção do LGBM\n",
    "lgb = LGBMClassifier(subsample = 0.7746298211333279, reg_lambda = 0.04676440937077718, reg_alpha = 5.937868749792548, num_leaves = 3, n_estimators = 100, min_split_gain = 16, min_child_weight = 378.8502727624012, min_child_samples = 1900, max_depth = 4, learning_rate = 0.012167884278142268, gamma = 4, colsample_bytree = 0.8332620063985445,\n",
    "random_state = 2022, # semente aleatória\n",
    "n_jobs = 10, # quantidade de processadores\n",
    "importance_type = 'gain'\n",
    ")\n",
    "lgb.fit(X_des[feats5], y_des) # Fit do modelo com o X e y de treino\n",
    "\n",
    "# Concat\n",
    "des = pd.concat([X_des, y_des], axis=1)\n",
    "val = pd.concat([X_val, y_val], axis=1)\n",
    "oot = pd.concat([X_oot, y_oot], axis=1)\n",
    "\n",
    "# Calcula P1 (vetor de probabilidades de ser mau)\n",
    "des['P1'] = lgb.predict_proba(des[feats5])[:, 1] # probabilidade do treino\n",
    "val['P1'] = lgb.predict_proba(val[feats5])[:, 1] # probabilidade do teste\n",
    "oot['P1'] = lgb.predict_proba(oot[feats5])[:, 1] # probabilidade da OOT\n",
    "\n",
    "# Print do KS em cada uma das amostras\n",
    "print('--> LightGBM')\n",
    "print(f\"KS TRAIN: {ks(des['RESPOSTA'], des['P1'])}\")\n",
    "print(f\"KS TEST:  {ks(val['RESPOSTA'], val['P1'])}\")\n",
    "print(f\"KS OOT:   {ks(oot['RESPOSTA'], oot['P1'])}\")\n",
    "\n",
    "# Empilhando\n",
    "df_scored = pd.concat([des, val, oot], ignore_index=True, axis=0)\n",
    "df_scored = df_scored.sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12.1. Cria decil de P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##https://stackoverflow.com/questions/20158597/how-to-qcut-with-non-unique-bin-edges\n",
    "df_scored['rank'] = df_scored['P1'].rank(method='first')\n",
    "df_scored['rnk_p1'] = pd.qcut(df_scored['rank'].values, 10).codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12.2. Maus por decil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inadimplência por Safra\n",
    "df2 = df_scored.groupby('rnk_p1')['RESPOSTA'].agg(['sum', 'count']).rename(columns={'sum':'Maus', 'count':'Total'})             # Agrupa conceito por safra\n",
    "df2.reset_index()\n",
    "df2['Bad_Rate'] = 100*(df2['Maus']/df2['Total'])\n",
    "df2['% Distr'] = df2['Total']/sum(df2['Total'])*100\n",
    "df2 = df2.reset_index();\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
